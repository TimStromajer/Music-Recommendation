{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Recommendation\n",
    "* A recommender system is a software tool and algorithm that gives recommendations for items\n",
    "- that are most interesting to a user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TYPES OF RECOMMENDATION SYSTEMS\n",
    "* Basically, we have two types of recommendation systems\n",
    "(1.) content-based filtering.\n",
    "(2.) collaborative-based filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*collaborative filtering: this is the process of predicting the interests of a user by - identifying preferences and information frommany users.\n",
    "\n",
    "*Content-based filtering: Content-based filtering gives recommendations based on the\n",
    "userâ€™s preference and profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###                       DATASET\n",
    "*For the purpose of our music recommendation algorithm, we acquired a kaggle Dataset that\n",
    "contains around 600,000 songs from Spotify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###                     ALGORITHM\n",
    "* Though we have three main Algorithm implemented in this project which are\n",
    "1. K-Clustering\n",
    "2. Birch-Clustering\n",
    "3. DBSCAN-Clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import spotipy\n",
    "import os\n",
    "\n",
    "import spotipy\n",
    "import pandas as pd\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import cdist\n",
    "import difflib\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "client_id = \"4813df40c194459085aed9c3ce7add62\"\n",
    "client_secret = \"a30fdf36eca04b9186c75432d4ae27f3\"\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id, client_secret))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data = pd.read_csv('./data/kaggle_spotify2/tracks.csv')\n",
    "spotify_data = spotify_data.replace({'year': '[0-9]{2}/[0-9]{2}/'}, {'year': ''}, regex=True)\n",
    "spotify_data = spotify_data.replace({'year': '-[0-9]{2}'}, {'year': ''}, regex=True)\n",
    "spotify_data['year'] = spotify_data['year'].astype(int)\n",
    "\n",
    "display(spotify_data.head())\n",
    "\n",
    "# save min and max for later normalization\n",
    "year_min = spotify_data[\"year\"].min()\n",
    "year_max = spotify_data[\"year\"].max()\n",
    "popularity_min = spotify_data[\"popularity\"].min()\n",
    "popularity_max = spotify_data[\"popularity\"].max()\n",
    "tempo_min = spotify_data[\"tempo\"].min()\n",
    "tempo_max = spotify_data[\"tempo\"].max()\n",
    "duration_ms_min = spotify_data[\"duration_ms\"].min()\n",
    "duration_ms_max = spotify_data[\"duration_ms\"].max()\n",
    "key_min = spotify_data[\"key\"].min()\n",
    "key_max = spotify_data[\"key\"].max()\n",
    "mode_min = spotify_data[\"mode\"].min()\n",
    "mode_max = spotify_data[\"mode\"].max()\n",
    "loudness_min = spotify_data[\"loudness\"].min()\n",
    "loudness_max = spotify_data[\"loudness\"].max()\n",
    "\n",
    "# normalize\n",
    "# spotify_data[\"year\"] = (spotify_data[\"year\"]-spotify_data[\"year\"].min())/(spotify_data[\"year\"].max()-spotify_data[\"year\"].min())\n",
    "spotify_data[\"popularity\"] = (spotify_data[\"popularity\"]-spotify_data[\"popularity\"].min())/(spotify_data[\"popularity\"].max()-spotify_data[\"popularity\"].min())\n",
    "spotify_data[\"tempo\"] = (spotify_data[\"tempo\"]-spotify_data[\"tempo\"].min())/(spotify_data[\"tempo\"].max()-spotify_data[\"tempo\"].min())\n",
    "spotify_data[\"duration_ms\"] = (spotify_data[\"duration_ms\"]-spotify_data[\"duration_ms\"].min())/(spotify_data[\"duration_ms\"].max()-spotify_data[\"duration_ms\"].min())\n",
    "spotify_data[\"key\"] = (spotify_data[\"key\"]-spotify_data[\"key\"].min())/(spotify_data[\"key\"].max()-spotify_data[\"key\"].min())\n",
    "spotify_data[\"mode\"] = (spotify_data[\"mode\"]-spotify_data[\"mode\"].min())/(spotify_data[\"mode\"].max()-spotify_data[\"mode\"].min())\n",
    "spotify_data[\"loudness\"] = (spotify_data[\"loudness\"]-spotify_data[\"loudness\"].min())/(spotify_data[\"loudness\"].max()-spotify_data[\"loudness\"].min())\n",
    "\n",
    "display(spotify_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the columns we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_params = ['valence', 'acousticness', 'danceability', 'duration_ms', 'energy', 'explicit',\n",
    " 'instrumentalness', 'key', 'liveness', 'loudness', 'mode', 'popularity', 'speechiness', 'tempo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find song data on spotify and normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_song_and_normalize(name, year=0, override_year=False):\n",
    "    song_data = defaultdict()\n",
    "    if year <= 1:\n",
    "        results = sp.search(q= 'track: {}'.format(name), limit=1)\n",
    "    else:\n",
    "        results = sp.search(q= 'track: {} year: {}'.format(name, year), limit=1)\n",
    "    if results['tracks']['items'] == []:\n",
    "        return None\n",
    "    \n",
    "    results = results['tracks']['items'][0]\n",
    "\n",
    "    track_id = results['id']\n",
    "    audio_features = sp.audio_features(track_id)[0]\n",
    "    \n",
    "    song_data['name'] = [name]\n",
    "    song_data['explicit'] = [int(results['explicit'])]\n",
    "    song_data['duration_ms'] = [results['duration_ms']]\n",
    "    song_data['popularity'] = [results['popularity']]\n",
    "    song_data['artists'] = [results['artists'][0]['name']]\n",
    "    song_data['year'] = [year]\n",
    "        \n",
    "    for key, value in audio_features.items():\n",
    "        song_data[key] = value\n",
    "        \n",
    "    # normalize\n",
    "    normalize_song(song_data)\n",
    "        \n",
    "    if override_year:\n",
    "        song_data['year'] = [year]\n",
    "    \n",
    "    return pd.DataFrame(song_data)\n",
    "\n",
    "\n",
    "def find_songs_and_normalize(songs, override_year=False):\n",
    "    result = []\n",
    "    frames = []\n",
    "    for s in songs:\n",
    "        if \"year\" not in s:\n",
    "            s[\"year\"] = 0\n",
    "        frame = find_song_and_normalize(s[\"name\"], s[\"year\"], override_year=override_year)\n",
    "        frames.append(frame)\n",
    "    try:\n",
    "        result = pd.concat(frames)\n",
    "        return result\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def normalize_song(song_data):\n",
    "    # song_data[\"year\"] = (song_data[\"year\"]-year_min)/(year_max-year_min)\n",
    "    song_data[\"popularity\"] = (song_data[\"popularity\"]-popularity_min)/(popularity_max-popularity_min)\n",
    "    song_data[\"tempo\"] = (song_data[\"tempo\"]-tempo_min)/(tempo_max-tempo_min)\n",
    "    song_data[\"duration_ms\"] = (song_data[\"duration_ms\"]-duration_ms_min)/(duration_ms_max-duration_ms_min)\n",
    "    song_data[\"key\"] = (song_data[\"key\"]-key_min)/(key_max-key_min)\n",
    "    song_data[\"mode\"] = (song_data[\"mode\"]-mode_min)/(mode_max-mode_min)\n",
    "    song_data[\"loudness\"] = (song_data[\"loudness\"]-loudness_min)/(loudness_max-loudness_min)\n",
    "    \n",
    "    return song_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example using spotipy find song function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# {'name': 'I\\'ll Be Waiting', 'year': 2011},\n",
    "a = \"Tessie\"\n",
    "song = find_song_and_normalize(a, year=2004)\n",
    "display(song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend songs functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the song data for a specific song. The song argument takes the form of a dictionary with \n",
    "# key-value pairs for the name and release year of the song.\n",
    "def get_song_data(song, spotify_data):\n",
    "    if 'year' not in song:\n",
    "        song['year'] = 0\n",
    "        \n",
    "    try:\n",
    "        song_data = spotify_data[(spotify_data['name'] == song['name']) \n",
    "                                & (spotify_data['year'] == song['year'])].iloc[0]\n",
    "        return song_data\n",
    "    \n",
    "    except IndexError:\n",
    "        return find_song_and_normalize(song['name'], song['year'])\n",
    "        \n",
    "\n",
    "# Gets the mean vector for a list of songs.\n",
    "def get_mean_vector(song_list_data):\n",
    "    song_vectors = []\n",
    "    for song in song_list_data.iterrows():\n",
    "        song_vector = song[1][used_params].values\n",
    "        song_vectors.append(song_vector)  \n",
    "    \n",
    "    song_matrix = np.array(list(song_vectors))\n",
    "    return np.mean(song_matrix, axis=0)\n",
    "\n",
    "# Utility function for flattening a list of dictionaries.\n",
    "def flatten_dict_list(dict_list):\n",
    "    flattened_dict = defaultdict()\n",
    "    for key in dict_list[0].keys():\n",
    "        flattened_dict[key] = []\n",
    "    \n",
    "    for dictionary in dict_list:\n",
    "        for key, value in dictionary.items():\n",
    "            flattened_dict[key].append(value)\n",
    "            \n",
    "    return flattened_dict\n",
    "       \n",
    "    \n",
    "# Recommends songs based on a list of previous songs that a user has listened to.\n",
    "def recommend_songs(song_list, spotify_data, pipeline, n_songs=10):\n",
    "    \n",
    "    metadata_cols = ['name', 'year', 'artists']\n",
    "    song_dict = flatten_dict_list(song_list)\n",
    "    \n",
    "    song_list_data = pd.DataFrame()\n",
    "    for song in song_list:\n",
    "        song_data = get_song_data(song, spotify_data)\n",
    "        song_list_data = song_list_data.append(song_data)\n",
    "    \n",
    "    song_list_data = song_list_data[used_params]\n",
    "    song_center = get_mean_vector(song_list_data)\n",
    "    \n",
    "    scaler = pipeline.steps[0][1]\n",
    "    scaled_data = scaler.transform(spotify_data[used_params])\n",
    "    scaled_song_center = scaler.transform(song_center.reshape(1, -1))\n",
    "    \n",
    "    distances = cdist(scaled_song_center, scaled_data, 'cosine')\n",
    "    index = list(np.argsort(distances)[:, :n_songs][0])\n",
    "    \n",
    "    rec_songs = spotify_data.iloc[index]\n",
    "    rec_songs = rec_songs[~rec_songs['name'].isin(song_dict['name'])]\n",
    "    return rec_songs[metadata_cols].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify cluster pipeline and fit it for the scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_cluster_pipeline_global = Pipeline([('scaler', StandardScaler()), \n",
    "                                  ('kmeans', KMeans(n_clusters=1))])\n",
    "X = spotify_data[used_params]\n",
    "song_cluster_pipeline_global.fit(X)\n",
    "scaler = song_cluster_pipeline_global.steps[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get spotify recommendation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract needed data from list of recomended spotify songs\n",
    "def spotifyRecomend_extractData(tracks):\n",
    "    res=[]    \n",
    "    for track in tracks['tracks']:   \n",
    "        trck={\n",
    "            'name': track['name'],\n",
    "            'artists': track['artists'][0]['name']\n",
    "            #'release_date': track['release_date'],\n",
    "            #'id': track['id']                              \n",
    "        }\n",
    "        res.append(trck)\n",
    "    #res2=pd.DataFrame.from_dict(res)    \n",
    "    return res\n",
    "\n",
    "\n",
    "#Number of songs which we will send to spotify recomondation function\n",
    "NUM_SpotifySng= 5\n",
    "def getSpotifyRecomendedSongs(listSongs, numOfRecc=3): #Input need to be DataFrame    \n",
    "    \n",
    "    #spotify_recomondation=[]\n",
    "    #display(listSongs)\n",
    "    #allRecomended=pd.DataFrame()\n",
    "    allRecomended=[]\n",
    "    # spotify function accepts max 5 songs, so we go through the list of songs and we divide them into groups ie we will \n",
    "    # first get recommended songs for the first 5 songs, then for the second 5 etc, and in the end for the rest of them (can be only 2 left)\n",
    "    while(len(listSongs)>0):        \n",
    "        if(len(listSongs)>NUM_SpotifySng):\n",
    "            first5Songs=listSongs.head(NUM_SpotifySng)\n",
    "            N = NUM_SpotifySng\n",
    "            listSongs = listSongs.tail(listSongs.shape[0] - N)\n",
    "        else:\n",
    "            first5Songs = listSongs\n",
    "            listSongs = listSongs.iloc[0:0]                        \n",
    "        \n",
    "        first5_ids = first5Songs['id'].values.tolist()    \n",
    "        spRc = sp.recommendations(seed_tracks=first5_ids, limit=numOfRecc)\n",
    "        recomendedNow = spotifyRecomend_extractData(spRc)\n",
    "        #allRecomended = pd.concat([allRecomended, recomendedNow], axis=0, ignore_index=True) \n",
    "        allRecomended += recomendedNow\n",
    "    return allRecomended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend songs and vector calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) close to average vector recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "song_list = [{'name': 'Come As You Are', 'year':1991},\n",
    "            {'name': 'Smells Like Teen Spirit', 'year': 1991},\n",
    "            {'name': 'Lithium', 'year': 1992},\n",
    "            {'name': 'All Apologies', 'year': 1993},\n",
    "            {'name': 'Stay Away', 'year': 1993}]\n",
    "input_songs_data = find_songs_and_normalize(song_list, override_year=True)\n",
    "rec_songs = recommend_songs(song_list, spotify_data, song_cluster_pipeline_global, 5)\n",
    "display(rec_songs)\n",
    "rec_songs_data = find_songs_and_normalize(rec_songs, override_year=True)\n",
    "display(rec_songs_data[used_params])\n",
    "rec_song_mean = get_mean_vector(rec_songs_data)\n",
    "\n",
    "fig = px.bar(input_songs_data, x='name', y=['valence', 'energy', 'danceability', 'acousticness', 'liveness'], barmode='group')\n",
    "fig.show()\n",
    "\n",
    "fig = px.bar(rec_songs_data, x='name', y=['valence', 'energy', 'danceability', 'acousticness', 'liveness'], barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Spotify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example using spotipy recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_list_data = pd.DataFrame()\n",
    "song_data = get_song_data({\"name\": \"Euphoria\", \"year\": 2012}, spotify_data)\n",
    "song_list_data = song_list_data.append(song_data)\n",
    "songs = getSpotifyRecomendedSongs(song_list_data)\n",
    "display(songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get spotify recommendations and calculate average vector distance n times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_list_data = pd.DataFrame()\n",
    "for song in song_list:\n",
    "    song_data = get_song_data(song, spotify_data)\n",
    "    song_list_data = song_list_data.append(song_data)\n",
    "vec_sum = 0\n",
    "for i in range(10):\n",
    "    recomenddet_spot = getSpotifyRecomendedSongs(song_list_data, numOfRecc=5)\n",
    "    #display(recomenddet_spot)\n",
    "    recomenddet_spot_song_data = find_songs_and_normalize(recomenddet_spot)\n",
    "    #display(recomenddet_spot_song_data[used_params])\n",
    "    rec_song_spotify_mean = get_mean_vector(recomenddet_spot_song_data)\n",
    "    \n",
    "    # Calculate vector distance\n",
    "    vec_dist = np.linalg.norm(rec_song_mean - rec_song_spotify_mean)\n",
    "    print(vec_dist)\n",
    "    vec_sum += vec_dist\n",
    "    \n",
    "vec_avg = vec_sum / 10\n",
    "print(\"avg vec: \" + str(vec_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Get average vector distance if we take 3 random songs from the data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random songs from data base\n",
    "avg_dist = 0\n",
    "for i in range(100):\n",
    "    samp1 = spotify_data.sample(n = 3)\n",
    "    samp2 = spotify_data.sample(n = 3)\n",
    "\n",
    "    mean1 = get_mean_vector(samp1)\n",
    "    mean2 = get_mean_vector(samp2)\n",
    "\n",
    "    vec_dist = np.linalg.norm(mean1 - mean2)\n",
    "    avg_dist += vec_dist\n",
    "print(avg_dist / 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Test recommendet songs subjectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(rec_songs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation on list with songs from different genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_list = [{'name': 'Come As You Are', 'year':1991},\n",
    "            {'name': 'Smells Like Teen Spirit', 'year': 1991},\n",
    "            {'name': 'Lithium', 'year': 1992},\n",
    "            {'name': 'Toxicity', 'year':2001},\n",
    "            {'name': 'Forest', 'year': 2001},\n",
    "            {'name': 'B.Y.O.B.', 'year': 2005},\n",
    "            {'name': 'Symphony No. 40 in G minor', 'year': 0},\n",
    "            {'name': 'Piano Concerto No. 21', 'year': 0},\n",
    "            {'name': 'Rondo for Piano in D Major, K. 485', 'year': 0},\n",
    "            {'name': 'Euphoria', 'year': 2012},\n",
    "            {'name': 'Hello', 'year': 2015},\n",
    "            {'name': 'Someone like you', 'year': 2011}]\n",
    "\n",
    "song_list = [{'name': 'Come As You Are', 'year':1991},\n",
    "            {'name': 'Smells Like Teen Spirit', 'year': 1991},\n",
    "            {'name': 'Lithium', 'year': 1991},\n",
    "            {'name': 'In Bloom', 'year': 1991},\n",
    "            {'name': 'Breed', 'year': 1991},\n",
    "            {'name': 'Polly', 'year': 1991},\n",
    "            {'name': 'Drain You', 'year': 1991},\n",
    "            {'name': 'Stay Away', 'year': 1991},\n",
    "            {'name': 'Something In The Way', 'year': 1991},\n",
    "            {'name': 'Territorial Pissings', 'year': 1991},\n",
    "            {'name': 'Lithium', 'year': 1991},\n",
    "\n",
    "            {'name': 'Toxicity', 'year':2001},\n",
    "            {'name': 'Forest', 'year': 2001},\n",
    "            {'name': 'Prison Song', 'year': 2001},\n",
    "            {'name': 'Deer dance', 'year': 2001},\n",
    "            {'name': 'X', 'year': 2001},\n",
    "            {'name': 'Needles', 'year': 2001},\n",
    "            {'name': 'Jet Pilot', 'year': 2001},\n",
    "            {'name': 'Chop Suey!', 'year': 2001},\n",
    "            {'name': 'Science', 'year': 2001},\n",
    "            {'name': 'Aerials', 'year': 2001},\n",
    "            {'name': 'Psycho', 'year': 2001},\n",
    "            {'name': 'B.Y.O.B.', 'year': 2005},\n",
    "\n",
    "            {'name': 'Symphony No. 40 in G minor', 'year': 0},\n",
    "            {'name': 'Piano Concerto No. 21', 'year': 0},\n",
    "            {'name': 'Rondo for Piano in D Major, K. 485', 'year': 0},\n",
    "\n",
    "            {'name': 'Someone like you', 'year': 2011},\n",
    "            {'name': 'Rolling in the Deep', 'year': 2011},\n",
    "            {'name': 'Rumour Has It', 'year': 2011},\n",
    "            {'name': 'Turning Tables', 'year': 2011},\n",
    "            #{'name': 'Don\\'t You Remember', 'year': 2011},\n",
    "            {'name': 'Set Fire to the Rain', 'year': 2011},\n",
    "            {'name': 'He Won\\'t Go', 'year': 2011},\n",
    "            {'name': 'Lovesong', 'year': 2011},\n",
    "            {'name': 'Take It All', 'year': 2011},\n",
    "            #{'name': 'I\\'ll Be Waiting', 'year': 2011},\n",
    "            {'name': 'Hello', 'year': 2015},\n",
    "\n",
    "            {'name': 'Promises', 'year': 2011},\n",
    "            {'name': '2808', 'year': 2011},\n",
    "            {'name': 'Doomsday', 'year': 2011},\n",
    "            #{'name': 'My Eyes', 'year': 2011},\n",
    "            #{'name': 'Guilt', 'year': 2011},\n",
    "            {'name': 'Fugue State', 'year': 2011},\n",
    "            #{'name': 'Me and You', 'year': 2011},\n",
    "            {'name': 'Innocence', 'year': 2011},\n",
    "            {'name': 'Crush on You', 'year': 2011},\n",
    "            {'name': 'Must Be the Feeling', 'year': 2011},\n",
    "            {'name': 'Reaching Out', 'year': 2011},\n",
    "            #{'name': 'Departure', 'year': 2011},\n",
    "\n",
    "            {'name': 'Without Me', 'year': 2002},\n",
    "            #{'name': 'White America', 'year': 2002},\n",
    "            {'name': 'Business', 'year': 2002},\n",
    "            {'name': 'Square Dance', 'year': 2002},\n",
    "            #{'name': 'Soldier', 'year': 2002},\n",
    "            {'name': 'Say Goodbye Hollywood', 'year': 2002},\n",
    "            {'name': 'Sing for the Moment', 'year': 2002},\n",
    "            {'name': 'Superman', 'year': 2002},\n",
    "            {'name': 'Hailie\\'s Song', 'year': 2002},\n",
    "            {'name': 'When the Music Stops', 'year': 2002},\n",
    "            {'name': 'Say What You Say', 'year': 2002},\n",
    "            {'name': 'Till I Collapse', 'year': 2002},\n",
    "\n",
    "            {'name': 'Someone You Loved', 'year': 2018},\n",
    "            {'name': 'Grace', 'year': 2019},\n",
    "            {'name': 'Bruises', 'year': 2017},\n",
    "            {'name': 'Hold Me While You Wait', 'year': 2019},\n",
    "            {'name': 'Lost on You', 'year': 2019},\n",
    "            #{'name': 'Fade', 'year': 2019},\n",
    "\n",
    "            {'name': 'No One', 'year': 2007},\n",
    "            {'name': 'Go Ahead', 'year': 2007},\n",
    "            {'name': 'Superwoman', 'year': 2007},\n",
    "            {'name': 'Like You\\'ll Never See Me Again', 'year': 2007},\n",
    "            {'name': 'Lesson Learned', 'year': 2007},\n",
    "            {'name': 'Wreckless Love', 'year': 2007},\n",
    "            {'name': 'The Thing About Love', 'year': 2007},\n",
    "            {'name': 'Teenage Love Affair', 'year': 2007},\n",
    "            #{'name': 'I Need You', 'year': 2007},\n",
    "            {'name': 'Where Do We Go from Here', 'year': 2007},\n",
    "\n",
    "            #{'name': 'I\\'m Shipping Up to Boston', 'year': 2006},\n",
    "            {'name': 'Tessie', 'year': 2004},\n",
    "            {'name': 'The Auld Triangle', 'year': 2005},\n",
    "            {'name': 'The Green Fields of France (No Man\\'s Land)', 'year': 2005},\n",
    "            {'name': 'Your Spirit\\'s Alive', 'year': 2005},\n",
    "\n",
    "            {'name': 'Shout', 'year': 1985},\n",
    "            {'name': 'The Working Hour', 'year': 1985},\n",
    "            {'name': 'Everybody Wants to Rule the World', 'year': 1985},\n",
    "            {'name': 'Mothers Talk', 'year': 1985},\n",
    "            {'name': 'I Believe', 'year': 1985},\n",
    "            #{'name': 'Broken', 'year': 1985},\n",
    "            {'name': 'Head over Heels', 'year': 1985},\n",
    "            #{'name': 'Listen', 'year': 1985},\n",
    "\n",
    "            {'name': 'Euphoria', 'year': 2012}]\n",
    "\n",
    "song_list_data = find_songs_and_normalize(song_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Obtain artist and album genres function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def album_artist_genres(name, year=0):\n",
    "    result = \"\"\n",
    "    if year == 0:\n",
    "        result = sp.search(q= 'track: {}'.format(name))\n",
    "    else:\n",
    "        result = sp.search(q= 'track: {}, year: {}'.format(name, year))\n",
    "        \n",
    "    # print(\"artist:\", result['tracks']['items'][0]['artists'][0][\"name\"])\n",
    "\n",
    "    result = sp.search(q= \"artist: {}\".format(result['tracks']['items'][0]['artists'][0][\"name\"]))\n",
    "    track = result['tracks']['items'][0]\n",
    "    \n",
    "    album = sp.album(track[\"album\"][\"external_urls\"][\"spotify\"])\n",
    "\n",
    "    artist = sp.artist(track[\"artists\"][0][\"external_urls\"][\"spotify\"])\n",
    "    \n",
    "    if len(album[\"genres\"]) > 0:\n",
    "        return album[\"genres\"]\n",
    "    else:\n",
    "        return artist[\"genres\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Determine the number of clusters by grouping songs in genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clusters = []\n",
    "for s in song_list:\n",
    "    print(s[\"name\"], s[\"year\"])\n",
    "    genres = album_artist_genres(s[\"name\"], s[\"year\"])\n",
    "    cluster_found = 0\n",
    "    for idx, c in enumerate(clusters):\n",
    "        intersection_set = set.intersection(set(genres), set(c))\n",
    "        \n",
    "        # check if some cluster has similar genres\n",
    "        if len(intersection_set) >= len(genres) / 4 or len(intersection_set) > len(c):\n",
    "            # merge lists\n",
    "            clusters[idx].extend(list(set(genres) - set(c)))\n",
    "            cluster_found = 1\n",
    "            \n",
    "    if cluster_found == 0:\n",
    "        # add new list\n",
    "        clusters.append(genres)\n",
    "            \n",
    "clusters_num = len(clusters)\n",
    "print(\"Clustered genres\")\n",
    "display(clusters)\n",
    "print(\"number of clusters:\", clusters_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Recommend songs for each cluster function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_clusters(song_list_data, clusters_num, pipeline):\n",
    "    allRecomendetSongs=[]\n",
    "    vec_sum = 0\n",
    "    for i in range(clusters_num):\n",
    "        print(\"### Cluster \" + str(i + 1) + \" ###\")\n",
    "        display(song_list_data.loc[song_list_data['cluster_label'] == i])\n",
    "        frame = song_list_data.loc[song_list_data['cluster_label'] == i]\n",
    "        song_list_cluster = []\n",
    "        for n,y in zip(frame[\"name\"], frame[\"year\"]):\n",
    "            song_list_cluster.append({\"name\": n, \"year\": y})\n",
    "            \n",
    "        rec_songs = recommend_songs(song_list_cluster, spotify_data, pipeline, 10)\n",
    "        rec_songs_data = find_songs_and_normalize(rec_songs, override_year=True)\n",
    "        # sort by popularity and get the most popular\n",
    "        rec_songs_data = rec_songs_data.sort_values(by=['popularity'], ascending=False)\n",
    "        rec_songs_data = rec_songs_data.head(5)\n",
    "        display(rec_songs_data[[\"name\", \"artists\"]])\n",
    "        if rec_songs_data is None:\n",
    "            print(\"Songs not found\")\n",
    "            continue\n",
    "        rec_song_mean = get_mean_vector(rec_songs_data)\n",
    "        \n",
    "        song_list_spotify_data = pd.DataFrame()\n",
    "        for song in song_list_cluster:\n",
    "            song_data = get_song_data(song, spotify_data)\n",
    "            song_list_spotify_data = song_list_spotify_data.append(song_data)\n",
    "        all_spotify_rec = []\n",
    "        for i in range(10):\n",
    "            recomenddet_spot = getSpotifyRecomendedSongs(song_list_spotify_data, numOfRecc=10)\n",
    "            all_spotify_rec += recomenddet_spot\n",
    "        recomenddet_spot_song_data = find_songs_and_normalize(all_spotify_rec)\n",
    "        rec_song_spotify_mean = get_mean_vector(recomenddet_spot_song_data)\n",
    "        \n",
    "        vec_dist = np.linalg.norm(rec_song_mean - rec_song_spotify_mean)\n",
    "        print(vec_dist)\n",
    "        vec_sum += vec_dist\n",
    "\n",
    "        # allRecomendetSongs += rec_songs\n",
    "        print(\"--------------------\")\n",
    "    vec_avg = vec_sum / clusters_num\n",
    "    print(\"Average vector: \" + str(vec_avg))\n",
    "    return allRecomendetSongs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) k-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def K_clustering(input_songs):\n",
    "\n",
    "    song_cluster_pipeline = Pipeline([('scaler', StandardScaler()), \n",
    "                                      ('kmeans', KMeans(n_clusters=clusters_num))])\n",
    "    X = spotify_data[used_params]\n",
    "    X2 = song_list_data[used_params]\n",
    "    song_cluster_pipeline.fit(X)\n",
    "    song_cluster_pipeline.fit(X2)\n",
    "    song_cluster_labels = song_cluster_pipeline.predict(X2)\n",
    "    song_list_data['cluster_label'] = song_cluster_labels\n",
    "\n",
    "    k_recomSongs = recommend_clusters(song_list_data, clusters_num, song_cluster_pipeline)\n",
    "    return k_recomSongs\n",
    "\n",
    "resK = K_clustering(song_list)\n",
    "table_birch = pd.DataFrame.from_dict(resK)\n",
    "display(table_birch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birch clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "song_list_data = find_songs_and_normalize(song_list)\n",
    "print(\"number of clusters:\", clusters_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Birch_clustering(input_songs):\n",
    "    \n",
    "    model = Birch(threshold=0.01, n_clusters=clusters_num)\n",
    "    X = spotify_data[used_params]\n",
    "    X2 = song_list_data[used_params]\n",
    "    #model.fit(X)\n",
    "    model.fit(X2)\n",
    "    song_cluster_labels = model.predict(X2)\n",
    "    song_list_data['cluster_label'] = song_cluster_labels\n",
    "    \n",
    "    # print(song_list_data[['name', 'cluster_label']])\n",
    "\n",
    "    k_recomSongs = recommend_clusters(song_list_data, clusters_num, song_cluster_pipeline_global)\n",
    "    return k_recomSongs\n",
    "\n",
    "resB = Birch_clustering(song_list)\n",
    "table_birch = pd.DataFrame.from_dict(resB)\n",
    "display(table_birch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "song_list_data = find_songs_and_normalize(song_list)\n",
    "print(\"number of clusters:\", clusters_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def DBSCAN_clustering(input_songs):\n",
    "    \n",
    "    model = DBSCAN(eps=0.7, min_samples=2)\n",
    "    X = spotify_data[used_params]\n",
    "    X2 = song_list_data[used_params]\n",
    "    # model.fit(X)\n",
    "    song_cluster_labels = model.fit_predict(X2)\n",
    "    song_list_data['cluster_label'] = song_cluster_labels\n",
    "    song_list_data['cluster_label'] = song_list_data['cluster_label'] + 1\n",
    "\n",
    "    cluster_num = song_list_data['cluster_label'].max() + 1\n",
    "\n",
    "    k_recomSongs = recommend_clusters(song_list_data, cluster_num, song_cluster_pipeline_global)\n",
    "    return k_recomSongs\n",
    "\n",
    "resDBS = DBSCAN_clustering(song_list)\n",
    "table_DBSCAN = pd.DataFrame.from_dict(resDBS)\n",
    "display(table_DBSCAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
